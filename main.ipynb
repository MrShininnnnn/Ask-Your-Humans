{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "33cfb311-121e-44e4-9c73-072fa4f11195",
   "metadata": {},
   "source": [
    "# CS7643 - Final Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60098e1b-b21f-4600-8c58-24f1246b09b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# built-in\n",
    "# public\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "# private\n",
    "from config import Config, InstrConfig\n",
    "from src.utils import dataloader, helpers\n",
    "from src.models.instructions_generator_model import InstructionsGeneratorModel\n",
    "from src.trainer import instructions_generator_trainer\n",
    "\n",
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc232721-5be3-4bbf-9540-61da89569cf1",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "745d277d-0f18-4e7c-b319-06cd98f8ecc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "instr_config = InstrConfig()\n",
    "helpers.set_seed(instr_config.random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9a897-713a-4fbf-b220-0f63f0b7667e",
   "metadata": {},
   "source": [
    "## Instructions Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7931b4b8-e729-4909-b8db-f8de736ed88d",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "757fefab-e97f-48f3-b2cc-b1505455244b",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e130e-ea81-4527-9770-021eea88c405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train size 202831\n",
    "# unique number of instructions 35921\n",
    "data = dataloader.load_pkl(workdir=instr_config.DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed3357b-a811-4d4d-89c3-f4169b145df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_states, train_inventories, train_actions, train_goals, train_instructions, all_instructions = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7e72ad-2df3-4d7e-9fa9-7dc66b4aa7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove invalid sample where train instruction is None\n",
    "invalid_index = set([i for i, _ in enumerate(train_instructions) if not _])\n",
    "print(len(invalid_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a5c2d0-e887-46a6-9274-a60b0d795ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_index = [i for i, _ in enumerate(train_instructions) if _]\n",
    "print(len(valid_index))\n",
    "train_states = np.array(train_states)[valid_index].tolist()\n",
    "train_inventories = np.array(train_inventories)[valid_index].tolist()\n",
    "train_actions = np.array(train_actions)[valid_index].tolist()\n",
    "train_instructions = np.array(train_instructions)[valid_index].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb91a46-3798-4c01-8b62-f670147755d7",
   "metadata": {},
   "source": [
    "### Build Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab423b2e-ae6c-4a8c-b0a4-95599f99aae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab, vocab_weights = dataloader.generate_vocab(\n",
    "    all_instructions, instr_config.device, workdir=instr_config.DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d3af4b-4cec-4695-90d9-4e5af2a9916b",
   "metadata": {},
   "source": [
    "### Generate Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7df324-3ba6-4e7d-a29f-d41bb960d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataloader.CraftingDataset(\n",
    "  instr_config.embeded_dim,\n",
    "  train_states,\n",
    "  train_inventories,\n",
    "  train_actions,\n",
    "  train_goals,\n",
    "  train_instructions,\n",
    "  vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a129d9-dea3-4ef0-a8f9-910141374914",
   "metadata": {},
   "outputs": [],
   "source": [
    "min([len(d[-1]) for d in dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f51a362-1954-469d-91d8-60fdd77808bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "instr_config.dataset_size = len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05ab357-1572-4751-98b0-dd5ce83561e0",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968db423-65aa-4254-94c5-c14546b56e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = list(range(instr_config.dataset_size))\n",
    "split = int(np.floor(instr_config.validation_split * instr_config.dataset_size))\n",
    "np.random.shuffle(indices)\n",
    "train_indices, val_indices = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "valid_sampler = SubsetRandomSampler(val_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db73dd1-9524-4742-a61a-345a0cb997d8",
   "metadata": {},
   "source": [
    "### Initialize Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf931ff-4f27-4531-bcc6-34b92d9e9bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_loader = DataLoader(\n",
    "  dataset,\n",
    "  batch_size=instr_config.batch_size,\n",
    "  num_workers=0,\n",
    "  pin_memory=True,\n",
    "  sampler=train_sampler,\n",
    "  collate_fn=dataloader.collate_fn)\n",
    "\n",
    "validation_data_loader = DataLoader(\n",
    "  dataset,\n",
    "  batch_size=instr_config.batch_size,\n",
    "  num_workers=0,\n",
    "  pin_memory=True,\n",
    "  sampler=valid_sampler,\n",
    "  collate_fn=dataloader.collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca36b8-d503-4424-ad6e-e98b8a3be5ff",
   "metadata": {},
   "source": [
    "### Setup Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c428d5-5bc8-442a-af5e-d76a3a0a12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InstructionsGeneratorModel(\n",
    "    instr_config.device\n",
    "    , len(vocab)\n",
    "    , instr_config.embeded_dim\n",
    "    , vocab_weights\n",
    ").to(instr_config.device)\n",
    "train = instructions_generator_trainer.train\n",
    "validate = instructions_generator_trainer.validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8a9ff60-9006-4a9f-be2c-dfc6dbb08f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CE Loss\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "# Adam\n",
    "parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "optimizer = torch.optim.Adam(parameters, lr=instr_config.learning_rate)\n",
    "# Log\n",
    "writer = SummaryWriter() if instr_config.summary_writer else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc28801e-c3d3-47f3-9df5-1c9ef56f3da3",
   "metadata": {},
   "source": [
    "### GO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9058ab-899c-42d7-9fbf-878144753789",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_loss = float('inf')\n",
    "valid_epoch, best_epoch = 0, None\n",
    "\n",
    "for epoch in range(instr_config.epochs):\n",
    "    # train\n",
    "    loss, bleu, tk_acc = train(\n",
    "        instr_config.device,\n",
    "        epoch,\n",
    "        train_data_loader,\n",
    "        model,\n",
    "        optimizer,\n",
    "        criterion,\n",
    "        parameters,\n",
    "        vocab,\n",
    "        summary_writer=writer)\n",
    "    print('Overall Epoch: %d, train loss: %.3f, train bleu: %.3f, train token acc: %.3f' % (epoch, loss, bleu, tk_acc))\n",
    "    # valid\n",
    "    loss, bleu, tk_acc = validate(\n",
    "        instr_config.device,\n",
    "        epoch,\n",
    "        validation_data_loader,\n",
    "        model,\n",
    "        criterion,\n",
    "        vocab,\n",
    "        summary_writer=writer)\n",
    "    print('Overall Epoch: %d, valid loss: %.3f, valid bleu: %.3f, valid token acc: %.3f' % (epoch, loss, bleu, tk_acc))\n",
    "    # early stopping\n",
    "    if loss <= best_valid_loss:\n",
    "        best_valid_loss = loss\n",
    "        valid_epoch, best_epoch = 0, epoch\n",
    "        torch.save(model.state_dict(), instr_config.SAVE_PATH)\n",
    "        print('Best Epoch: %d, best valid loss: %.3f' % (best_epoch, best_valid_loss))\n",
    "        print('Trained model saved at ', instr_config.SAVE_PATH)\n",
    "    else:\n",
    "        valid_epoch += 1\n",
    "        if valid_epoch >= instr_config.valid_patience:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab4f00b-5a94-4653-892b-3a485dae913b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
